{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f976b6e-0a62-454d-8057-000f0b465630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc2971f9-a2d0-4c67-b17f-582870b3c3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(id='resp_680854dc2ccc81919a8e797a7e8124da05851bf7fd48e61b', created_at=1745376476.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseOutputMessage(id='msg_680854de6c088191af8346ed33150ca505851bf7fd48e61b', content=[ResponseOutputText(annotations=[], text='Under a blanket of twinkling stars, a gentle unicorn tiptoed through a silver forest, spreading dreams of sparkling magic to all who slept nearby.', type='output_text')], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, max_output_tokens=None, previous_response_id=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=32, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=50), user=None, store=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing api\n",
    "system_instructions = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an assistant that's helping me with this research project. The structure of this project is that we have had undergraduates label traits of images manually. These traits include things like ontology, substrates, font information, text, covid-relation, confidence, and more. You are now going to be doing what they have been doing. When provided with an image, you should return a json object that describes the image according to the structure given here. The structure you should return as is provided below, along with an example. Keep in mind there can be multiple substrates (up to 4), with multiple fonts for each substrate (up to 8). Many of the images will have multiple substrates, look closely in the images for any other substrates which are clear and sharp. For information on what each possible field can mean and examples of each, refer to the files you have available. When annotating the text that is in the image, ensure that the markdown guide that you have available to you is used to record the text.\n",
    "    \n",
    "        This is the format you should return to me in, with comments denoting the purpose of the field for some:\n",
    "    \n",
    "        |||{return format}\n",
    "        {\n",
    "            \"substrateCount\": // the number of substrates in this image,\n",
    "            \"substrates\": [\n",
    "                {\n",
    "                    \"placement\": // refer to placement examples in screenshots of form,\n",
    "                    \"additionalNotes\": // not always necessary to include,\n",
    "                    \"thisIsntReallyASign\": // set this field to true if this doesn't really fit any of the placement categories and isn't a sign, else false,\n",
    "                    \"notASignDescription\": // use this if the previous field was true, describe the placement,\n",
    "                    \"typefaces\": [\n",
    "                        {\n",
    "                            \"typefaceStyle\": [], // can be multiple, choose from the options provided to you below,\n",
    "                            \"copy\": // make sure that the text is annotated according to the markdown guide in one of the screenshots provided to you,\n",
    "                            \"letteringOntology\": [], // refer to the OC Fonts: Codebook Descriptions & Photo Examples file for examples and descriptions of what each of these are,\n",
    "                            \"messageFunction\": // again refer to the OC Fonts: Codebook Descriptions & Photo Examples file for examples and descriptions of what each of these are,\n",
    "                            \"covidRelated\": // is this text covid related?,\n",
    "                            \"additionalNotes\": // any additional notes needed about this image\n",
    "                        }\n",
    "                    ],\n",
    "                    \"confidence\": // overall confidence in your annotation, 0 being the lowest, 5 the highest,\n",
    "                    \"confidenceReasoning\": // reasoning for confidence rating,\n",
    "                    \"additionalInfo\": // any additional info about the substrate, not always necessary to include\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        |||\n",
    "    \n",
    "        This is an example of the returned product you should give to me. This example only has one substrate but other images may have multiple.\n",
    "    \n",
    "        |||{return example}\n",
    "        {\n",
    "            \"substrateCount\": 1,\n",
    "            \"substrates\": [\n",
    "                {\n",
    "                    \"placement\": \"Window-stuck\",\n",
    "                    \"additionalNotes\": \"decal stickers on a parking meter\",\n",
    "                    \"thisIsntReallyASign\": false,\n",
    "                    \"notASignDescription\": \"\",\n",
    "                    \"typefaces\": [\n",
    "                        {\n",
    "                            \"typefaceStyle\": [\"Serif\", \"Stylized\"],\n",
    "                            \"copy\": \"Please, no food or\\\\ndrink in the store.\\\\nThank You!\",\n",
    "                            \"letteringOntology\": [\"Painted\", \"Pan-face\"],\n",
    "                            \"messageFunction\": \"Operational information\",\n",
    "                            \"covidRelated\": false,\n",
    "                            \"additionalNotes\": \"Text is center aligned, \\\\\\\"OPEN\\\\\\\" is larger than \\\\\\\"5PM DAILY\\\\\\\"\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"confidence\": 4,\n",
    "                    \"confidenceReasoning\": \"Could be painted or pan-face or both\",\n",
    "                    \"additionalInfo\": \"Image heavily cut off\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        |||\n",
    "    \n",
    "        These are some of the options for message function, typeface style, ontology and placements:\n",
    "    \n",
    "        |||{\n",
    "            \"typeface\": [\n",
    "                \"Serif\", \"Sans serif\", \"Slab serif\", \"Script\", \"Stylized\", \"Quirky\"\n",
    "            ],\n",
    "            \"lettering_ontology\": [\n",
    "                \"Printed\", \"Decal\", \"Painted\", \"Pan channel\", \"Pan face\", \"Handmade\",\n",
    "                \"Embossed\", \"Debossed\", \"Pen or marker\", \"Reader board\", \"Spray paint\",\n",
    "                \"LED\", \"Other electronic\", \"Neon\", \"Tile\", \"Chalk\", \"House number\", \"Ghost sign\"\n",
    "            ],\n",
    "            \"placements\": [\n",
    "                \"Window-stuck\", \"Window-placed\", \"Awning/canopy\", \"Blade\", \"Fascia\",\n",
    "                \"Marquee\", \"Hanging\", \"Name-plate\", \"Painted wall\", \"Freestanding\",\n",
    "                \"Parapet\", \"Ground\", \"Bench\", \"Flag\", \"Pole-mounted\", \"Post and panel\",\n",
    "                \"Pylon\", \"Banner\", \"Wall-placed\", \"Wall-stuck\", \"Other-stuck\", \"Snipe\",\n",
    "                \"Graffiti\", \"Infrastructure\", \"Memorial\", \"Sticker\"\n",
    "            ],\n",
    "            \"message_function\": [\n",
    "                \"Identification\", \"Address\", \"Joint tenant\", \"Operational information\",\n",
    "                \"Advisement/regulation\", \"Directory\", \"Generic information\", \"Menu of options\",\n",
    "                \"Commemoration\", \"Street name\", \"Advertisement\", \"Wayfinding\", \"Infrastructure\",\n",
    "                \"Covid-related\"\n",
    "            ]\n",
    "        }|||\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81333bee-bea6-41d1-949f-e42d1479eb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158 images in images/Garden Grove\n",
      "Processing...\n",
      "Successfully processed 158 images into 4 separate files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "template = {\n",
    "    \"custom_id\": \"\",\n",
    "    \"method\": \"POST\",\n",
    "    \"url\": \"/v1/chat/completions\",\n",
    "    \"body\": {\n",
    "        \"model\": \"gpt-4.1\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_instructions\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"image goes here\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "    \n",
    "def encode_image(images_dir, image_name):\n",
    "    '''\n",
    "    Encodes an image into base64 so it can be stored in a jsonl file\n",
    "    '''\n",
    "\n",
    "    # find image\n",
    "    root_path = Path(images_dir)\n",
    "    for file in root_path.rglob(image_name):  # rglob() searches recursively\n",
    "        with open(str(file), \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "    print(f\"Skipping an image, unable to find {image_name}\")\n",
    "    return None\n",
    "\n",
    "def create_batch_object(images_path, image_extensions, output_file_name):\n",
    "    \n",
    "    # Get all files in the directory (no subfolders)\n",
    "    image_files = [\n",
    "        f for f in os.listdir(images_path)\n",
    "        if os.path.isfile(os.path.join(images_path, f)) and os.path.splitext(f)[1].lower() in image_extensions\n",
    "    ]\n",
    "    output_files = []\n",
    "    \n",
    "    print(\"Found\", len(image_files), \"images in\", images_path)\n",
    "    print(\"Processing...\")\n",
    "    name_ptr = 0  # ptr for image_files\n",
    "    i = 0\n",
    "    while name_ptr < len(image_files):\n",
    "        with open(f\"{output_file_name}{i}.jsonl\", \"w\") as file:\n",
    "            output_files.append(f\"{output_file_name}{i}.jsonl\")\n",
    "            while name_ptr < len(image_files):\n",
    "                filename = image_files[name_ptr]\n",
    "                template[\"custom_id\"] = filename.lower()\n",
    "                base64_image = encode_image(folder_path, filename)\n",
    "                template[\"body\"][\"messages\"][1][\"content\"] = [{\n",
    "                                    \"type\": \"image_url\",\n",
    "                                    \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "                                }]\n",
    "                file.write(json.dumps(template) + '\\n')\n",
    "                name_ptr += 1\n",
    "                if name_ptr % 40 == 0:  # break on every x number of examples\n",
    "                    break\n",
    "        i += 1\n",
    "        \n",
    "    print(\"Successfully processed\", len(image_files), \"images into\", i, \"separate files\")\n",
    "    return output_files\n",
    "        \n",
    "images_path = 'images/Garden Grove'\n",
    "image_extensions = {'.JPG', '.jpg', '.jpeg'}\n",
    "output_file_name = \"batchGardenGrove\" \n",
    "\n",
    "output_files = create_batch_object(images_path, image_extensions, output_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2eaee32d-d778-4363-8141-426b5a6e5fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload of 4 files\n",
      "Finished uploading file 0\n",
      "Finished uploading file 1\n",
      "Finished uploading file 2\n",
      "Finished uploading file 3\n",
      "File ids are ['file-1HH2VdGKdgXTZSniSsrL3x', 'file-ML4sC4PgNLAVnfipGz9Kd5', 'file-JJDzCU8CovnpU45tT4Vche', 'file-Hqv4QVaHbMqHDPDffNq6b9']\n",
      "Now starting batch jobs\n",
      "Queued batch job 0\n",
      "Queued batch job 1\n",
      "Queued batch job 2\n",
      "Queued batch job 3\n"
     ]
    }
   ],
   "source": [
    "def sendToOpenAI(output_files):\n",
    "    file_ids = []\n",
    "    client = OpenAI()\n",
    "    print(\"Starting upload of\", len(output_files), \"files\")\n",
    "    for i in range(len(output_files)):\n",
    "        filename = output_files[i]\n",
    "        file_ids.append(client.files.create(\n",
    "            file=open(filename, \"rb\"),\n",
    "            purpose=\"batch\"\n",
    "        ).id)\n",
    "        print(f\"Finished uploading file {i + 1}\")\n",
    "    print(\"File ids are\", file_ids)\n",
    "    print(\"Now starting batch jobs\")\n",
    "    for i in range(len(file_ids)):\n",
    "        file_id = file_ids[i]\n",
    "        client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\",\n",
    "            metadata={\n",
    "                \"description\": \"one of many garden grove jobs\"\n",
    "            }\n",
    "        )\n",
    "        print(f\"Queued batch job {i + 1}\")\n",
    "\n",
    "sendToOpenAI(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc4fafd-369a-4f45-b6a1-35b65992f2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3be188-00b9-424d-bb07-3c5faeb1102e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs178",
   "language": "python",
   "name": "cs178"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
